{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_review_test1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTFnc0tLE8MF/X/lIlTud+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimaMirana/DataAnalysisWithPython/blob/master/IMDB_review_test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqWLAFm_4tHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c625c26-2ed8-4469-925c-9e0a682ba6a2"
      },
      "source": [
        "#check version of tensor\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi2Sg5cv-9HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n",
        "#print(imdb.keys()) #dict_keys(['test', 'train', 'unsupervised'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBLSaRhW_A_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = imdb['train'], imdb['test']\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "# merge default train test for spliting it into 80/20 later\n",
        "for s,l in train_data:\n",
        "  sentences.append(str(s.numpy()))\n",
        "  labels.append(l.numpy())\n",
        "  \n",
        "for s,l in test_data:\n",
        "  sentences.append(str(s.numpy()))\n",
        "  labels.append(l.numpy())\n",
        "  \n",
        "#convert str to np array\n",
        "sentences_final = np.array(sentences) \n",
        "labels_final = np.array(labels)\n",
        "\n",
        "#print(len(sentences_final)) #50000\n",
        "#print(labels_final)\n",
        "\n",
        "# x = max([len(v) for v in training_sentences]) #get maximum review lingth\n",
        "# print(x) #13747\n",
        "# print(training_sentences[13747])\n",
        "# print(len(training_sentences[13747]))\n",
        "# print(training_labels_final[13747])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR162CuGAFoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(np.unique(labels_final)) # [0 1]\n",
        "#print(len(np.unique(np.hstack(sentences_final)))) #49582 no of unique words\n",
        "# review_length = [len(i) for i in sentences_final] #get all the length of each review stack in an array\n",
        "#print(np.max(review_length)) #max review length 13741\n",
        "#print(np.min(review_length)) #min review length 35\n",
        "#print(np.mean(review_length)) #avg review length 1371.00638\n",
        "#print(round(np.std(length))) #standard deviation 995.0\n",
        "#print(sentences_final[0]) #This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAg0eXfdOhVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_size=50000\n",
        "test_portion=.8\n",
        "split = int(training_size * test_portion)\n",
        "vocab_size = 50000\n",
        "embedding_dim = 16\n",
        "max_length = 13741\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WxbNC7Fg1_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_sentences = sentences[0:split]\n",
        "testing_sentences = sentences[split:]\n",
        "training_labels = labels[0:split]\n",
        "testing_labels = labels[split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBrzz3FseHVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAmV-TL-lfBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Need this block to get it to work with TensorFlow 2.x\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41tRvzdJeJdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "#print(decode_review(training_padded[2])) #padded review in str\n",
        "#print(training_sentences[2]) #raw review in str\n",
        "#print(training_labels[2]) #label for that review\n",
        "#print(testing_sentences[1])\n",
        "#print(testing_labels[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6z_VXLFiqQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hidden layer1->global avg pooling\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Pe1oaf7mKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d7369b9-d831-479e-86ab-af8b306cde2a"
      },
      "source": [
        "num_epochs = 30\n",
        "batch_size = 10\n",
        "history = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4000/4000 - 74s - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6800 - val_accuracy: 0.7436\n",
            "Epoch 2/30\n",
            "4000/4000 - 74s - loss: 0.5572 - accuracy: 0.7329 - val_loss: 0.4310 - val_accuracy: 0.8346\n",
            "Epoch 3/30\n",
            "4000/4000 - 73s - loss: 0.3784 - accuracy: 0.8434 - val_loss: 0.4274 - val_accuracy: 0.7882\n",
            "Epoch 4/30\n",
            "4000/4000 - 73s - loss: 0.3154 - accuracy: 0.8708 - val_loss: 0.2984 - val_accuracy: 0.8831\n",
            "Epoch 5/30\n",
            "4000/4000 - 73s - loss: 0.2829 - accuracy: 0.8858 - val_loss: 0.2831 - val_accuracy: 0.8880\n",
            "Epoch 6/30\n",
            "4000/4000 - 73s - loss: 0.2622 - accuracy: 0.8961 - val_loss: 0.2691 - val_accuracy: 0.8933\n",
            "Epoch 7/30\n",
            "4000/4000 - 74s - loss: 0.2436 - accuracy: 0.9046 - val_loss: 0.2780 - val_accuracy: 0.8861\n",
            "Epoch 8/30\n",
            "4000/4000 - 73s - loss: 0.2286 - accuracy: 0.9105 - val_loss: 0.2534 - val_accuracy: 0.9013\n",
            "Epoch 9/30\n",
            "4000/4000 - 73s - loss: 0.2148 - accuracy: 0.9177 - val_loss: 0.2590 - val_accuracy: 0.8956\n",
            "Epoch 10/30\n",
            "4000/4000 - 76s - loss: 0.2032 - accuracy: 0.9208 - val_loss: 0.2782 - val_accuracy: 0.8890\n",
            "Epoch 11/30\n",
            "4000/4000 - 75s - loss: 0.1961 - accuracy: 0.9244 - val_loss: 0.2678 - val_accuracy: 0.8940\n",
            "Epoch 12/30\n",
            "4000/4000 - 74s - loss: 0.1870 - accuracy: 0.9287 - val_loss: 0.3353 - val_accuracy: 0.8627\n",
            "Epoch 13/30\n",
            "4000/4000 - 73s - loss: 0.1796 - accuracy: 0.9306 - val_loss: 0.2705 - val_accuracy: 0.8931\n",
            "Epoch 14/30\n",
            "4000/4000 - 73s - loss: 0.1685 - accuracy: 0.9374 - val_loss: 0.3231 - val_accuracy: 0.8762\n",
            "Epoch 15/30\n",
            "4000/4000 - 73s - loss: 0.1628 - accuracy: 0.9401 - val_loss: 0.2493 - val_accuracy: 0.9053\n",
            "Epoch 16/30\n",
            "4000/4000 - 73s - loss: 0.1558 - accuracy: 0.9416 - val_loss: 0.3060 - val_accuracy: 0.8818\n",
            "Epoch 17/30\n",
            "4000/4000 - 73s - loss: 0.1521 - accuracy: 0.9438 - val_loss: 0.2780 - val_accuracy: 0.8946\n",
            "Epoch 18/30\n",
            "4000/4000 - 74s - loss: 0.1427 - accuracy: 0.9464 - val_loss: 0.2952 - val_accuracy: 0.8928\n",
            "Epoch 19/30\n",
            "4000/4000 - 74s - loss: 0.1388 - accuracy: 0.9483 - val_loss: 0.3579 - val_accuracy: 0.8730\n",
            "Epoch 20/30\n",
            "4000/4000 - 74s - loss: 0.1353 - accuracy: 0.9508 - val_loss: 0.3088 - val_accuracy: 0.8868\n",
            "Epoch 21/30\n",
            "4000/4000 - 74s - loss: 0.1280 - accuracy: 0.9529 - val_loss: 0.2571 - val_accuracy: 0.9075\n",
            "Epoch 22/30\n",
            "4000/4000 - 74s - loss: 0.1284 - accuracy: 0.9526 - val_loss: 0.2592 - val_accuracy: 0.9078\n",
            "Epoch 23/30\n",
            "4000/4000 - 74s - loss: 0.1217 - accuracy: 0.9545 - val_loss: 0.2692 - val_accuracy: 0.9052\n",
            "Epoch 24/30\n",
            "4000/4000 - 75s - loss: 0.1148 - accuracy: 0.9579 - val_loss: 0.2685 - val_accuracy: 0.9053\n",
            "Epoch 25/30\n",
            "4000/4000 - 74s - loss: 0.1145 - accuracy: 0.9577 - val_loss: 0.2816 - val_accuracy: 0.9020\n",
            "Epoch 26/30\n",
            "4000/4000 - 73s - loss: 0.1099 - accuracy: 0.9605 - val_loss: 0.2752 - val_accuracy: 0.9058\n",
            "Epoch 27/30\n",
            "4000/4000 - 74s - loss: 0.1060 - accuracy: 0.9618 - val_loss: 0.3013 - val_accuracy: 0.8971\n",
            "Epoch 28/30\n",
            "4000/4000 - 74s - loss: 0.1023 - accuracy: 0.9622 - val_loss: 0.2887 - val_accuracy: 0.9032\n",
            "Epoch 29/30\n",
            "4000/4000 - 73s - loss: 0.1002 - accuracy: 0.9636 - val_loss: 0.8236 - val_accuracy: 0.7926\n",
            "Epoch 30/30\n",
            "4000/4000 - 73s - loss: 0.0984 - accuracy: 0.9645 - val_loss: 0.3406 - val_accuracy: 0.8911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_X6nUBYnqHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b60e6785-f97d-492d-98d3-5f3457bbf774"
      },
      "source": [
        "num_epochs = 50\n",
        "batch_size = 8\n",
        "history6 = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5000/5000 - 79s - loss: 0.6904 - accuracy: 0.5269 - val_loss: 0.6710 - val_accuracy: 0.6144\n",
            "Epoch 2/50\n",
            "5000/5000 - 80s - loss: 0.5514 - accuracy: 0.7394 - val_loss: 0.4383 - val_accuracy: 0.8210\n",
            "Epoch 3/50\n",
            "5000/5000 - 80s - loss: 0.3808 - accuracy: 0.8404 - val_loss: 0.3354 - val_accuracy: 0.8683\n",
            "Epoch 4/50\n",
            "5000/5000 - 80s - loss: 0.3141 - accuracy: 0.8733 - val_loss: 0.2976 - val_accuracy: 0.8834\n",
            "Epoch 5/50\n",
            "5000/5000 - 80s - loss: 0.2824 - accuracy: 0.8864 - val_loss: 0.2795 - val_accuracy: 0.8884\n",
            "Epoch 6/50\n",
            "5000/5000 - 81s - loss: 0.2621 - accuracy: 0.8950 - val_loss: 0.3348 - val_accuracy: 0.8554\n",
            "Epoch 7/50\n",
            "5000/5000 - 81s - loss: 0.2422 - accuracy: 0.9042 - val_loss: 0.2565 - val_accuracy: 0.8982\n",
            "Epoch 8/50\n",
            "5000/5000 - 80s - loss: 0.2301 - accuracy: 0.9096 - val_loss: 0.2611 - val_accuracy: 0.8939\n",
            "Epoch 9/50\n",
            "5000/5000 - 80s - loss: 0.2162 - accuracy: 0.9160 - val_loss: 0.2491 - val_accuracy: 0.9030\n",
            "Epoch 10/50\n",
            "5000/5000 - 80s - loss: 0.2046 - accuracy: 0.9204 - val_loss: 0.2422 - val_accuracy: 0.9066\n",
            "Epoch 11/50\n",
            "5000/5000 - 79s - loss: 0.1989 - accuracy: 0.9229 - val_loss: 0.2437 - val_accuracy: 0.9035\n",
            "Epoch 12/50\n",
            "5000/5000 - 79s - loss: 0.1876 - accuracy: 0.9279 - val_loss: 0.2390 - val_accuracy: 0.9080\n",
            "Epoch 13/50\n",
            "5000/5000 - 78s - loss: 0.1783 - accuracy: 0.9325 - val_loss: 0.2403 - val_accuracy: 0.9053\n",
            "Epoch 14/50\n",
            "5000/5000 - 80s - loss: 0.1718 - accuracy: 0.9350 - val_loss: 0.2442 - val_accuracy: 0.9044\n",
            "Epoch 15/50\n",
            "5000/5000 - 79s - loss: 0.1683 - accuracy: 0.9365 - val_loss: 0.2362 - val_accuracy: 0.9090\n",
            "Epoch 16/50\n",
            "5000/5000 - 79s - loss: 0.1600 - accuracy: 0.9395 - val_loss: 0.2992 - val_accuracy: 0.8839\n",
            "Epoch 17/50\n",
            "5000/5000 - 80s - loss: 0.1552 - accuracy: 0.9423 - val_loss: 0.2375 - val_accuracy: 0.9087\n",
            "Epoch 18/50\n",
            "5000/5000 - 79s - loss: 0.1492 - accuracy: 0.9433 - val_loss: 0.2393 - val_accuracy: 0.9093\n",
            "Epoch 19/50\n",
            "5000/5000 - 78s - loss: 0.1408 - accuracy: 0.9483 - val_loss: 0.3641 - val_accuracy: 0.8588\n",
            "Epoch 20/50\n",
            "5000/5000 - 78s - loss: 0.1395 - accuracy: 0.9486 - val_loss: 0.2462 - val_accuracy: 0.9080\n",
            "Epoch 21/50\n",
            "5000/5000 - 79s - loss: 0.1356 - accuracy: 0.9486 - val_loss: 0.2684 - val_accuracy: 0.9001\n",
            "Epoch 22/50\n",
            "5000/5000 - 80s - loss: 0.1294 - accuracy: 0.9517 - val_loss: 0.2545 - val_accuracy: 0.9066\n",
            "Epoch 23/50\n",
            "5000/5000 - 79s - loss: 0.1258 - accuracy: 0.9541 - val_loss: 0.2822 - val_accuracy: 0.8987\n",
            "Epoch 24/50\n",
            "5000/5000 - 79s - loss: 0.1247 - accuracy: 0.9539 - val_loss: 0.2643 - val_accuracy: 0.9021\n",
            "Epoch 25/50\n",
            "5000/5000 - 79s - loss: 0.1198 - accuracy: 0.9552 - val_loss: 0.2753 - val_accuracy: 0.8992\n",
            "Epoch 26/50\n",
            "5000/5000 - 79s - loss: 0.1120 - accuracy: 0.9585 - val_loss: 0.2864 - val_accuracy: 0.8985\n",
            "Epoch 27/50\n",
            "5000/5000 - 79s - loss: 0.1095 - accuracy: 0.9586 - val_loss: 0.3175 - val_accuracy: 0.8923\n",
            "Epoch 28/50\n",
            "5000/5000 - 79s - loss: 0.1075 - accuracy: 0.9609 - val_loss: 0.2865 - val_accuracy: 0.8977\n",
            "Epoch 29/50\n",
            "5000/5000 - 79s - loss: 0.1043 - accuracy: 0.9617 - val_loss: 0.2705 - val_accuracy: 0.9059\n",
            "Epoch 30/50\n",
            "5000/5000 - 79s - loss: 0.0988 - accuracy: 0.9642 - val_loss: 0.2750 - val_accuracy: 0.9051\n",
            "Epoch 31/50\n",
            "5000/5000 - 77s - loss: 0.1022 - accuracy: 0.9628 - val_loss: 0.3716 - val_accuracy: 0.8732\n",
            "Epoch 32/50\n",
            "5000/5000 - 79s - loss: 0.0917 - accuracy: 0.9672 - val_loss: 0.3345 - val_accuracy: 0.8865\n",
            "Epoch 33/50\n",
            "5000/5000 - 79s - loss: 0.0921 - accuracy: 0.9674 - val_loss: 0.2863 - val_accuracy: 0.9041\n",
            "Epoch 34/50\n",
            "5000/5000 - 80s - loss: 0.0902 - accuracy: 0.9671 - val_loss: 0.3185 - val_accuracy: 0.8974\n",
            "Epoch 35/50\n",
            "5000/5000 - 79s - loss: 0.0882 - accuracy: 0.9688 - val_loss: 0.3282 - val_accuracy: 0.8969\n",
            "Epoch 36/50\n",
            "5000/5000 - 79s - loss: 0.0878 - accuracy: 0.9679 - val_loss: 0.2973 - val_accuracy: 0.9046\n",
            "Epoch 37/50\n",
            "5000/5000 - 78s - loss: 0.0843 - accuracy: 0.9691 - val_loss: 0.4064 - val_accuracy: 0.8729\n",
            "Epoch 38/50\n",
            "5000/5000 - 79s - loss: 0.0811 - accuracy: 0.9705 - val_loss: 0.3017 - val_accuracy: 0.9032\n",
            "Epoch 39/50\n",
            "5000/5000 - 77s - loss: 0.0810 - accuracy: 0.9703 - val_loss: 0.3062 - val_accuracy: 0.9007\n",
            "Epoch 40/50\n",
            "5000/5000 - 79s - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.3115 - val_accuracy: 0.9014\n",
            "Epoch 41/50\n",
            "5000/5000 - 79s - loss: 0.0774 - accuracy: 0.9723 - val_loss: 0.3461 - val_accuracy: 0.8969\n",
            "Epoch 42/50\n",
            "5000/5000 - 79s - loss: 0.0723 - accuracy: 0.9732 - val_loss: 0.3900 - val_accuracy: 0.8855\n",
            "Epoch 43/50\n",
            "5000/5000 - 79s - loss: 0.0702 - accuracy: 0.9747 - val_loss: 0.3505 - val_accuracy: 0.8990\n",
            "Epoch 44/50\n",
            "5000/5000 - 79s - loss: 0.0727 - accuracy: 0.9734 - val_loss: 0.5174 - val_accuracy: 0.8643\n",
            "Epoch 45/50\n",
            "5000/5000 - 79s - loss: 0.0722 - accuracy: 0.9736 - val_loss: 0.3314 - val_accuracy: 0.8990\n",
            "Epoch 46/50\n",
            "5000/5000 - 79s - loss: 0.0703 - accuracy: 0.9751 - val_loss: 0.4007 - val_accuracy: 0.8846\n",
            "Epoch 47/50\n",
            "5000/5000 - 78s - loss: 0.0656 - accuracy: 0.9764 - val_loss: 0.3585 - val_accuracy: 0.9002\n",
            "Epoch 48/50\n",
            "5000/5000 - 79s - loss: 0.0647 - accuracy: 0.9768 - val_loss: 0.3354 - val_accuracy: 0.9006\n",
            "Epoch 49/50\n",
            "5000/5000 - 78s - loss: 0.0615 - accuracy: 0.9770 - val_loss: 0.3892 - val_accuracy: 0.8977\n",
            "Epoch 50/50\n",
            "5000/5000 - 79s - loss: 0.0618 - accuracy: 0.9770 - val_loss: 0.3818 - val_accuracy: 0.8961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muh-ZzM9HTYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hidden layer1->global avg pooling\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(32, kernel_initializer='lecun_normal', activation='selu'),\n",
        "    tf.keras.layers.AlphaDropout(0.01),\n",
        "    tf.keras.layers.Dense(16, kernel_initializer='lecun_normal', activation='selu'),\n",
        "    tf.keras.layers.AlphaDropout(0.01),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUmVH5CoHaNz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "35c48c00-006b-47ee-da1a-2523c985a8bc"
      },
      "source": [
        "num_epochs = 20\n",
        "batch_size = 10\n",
        "history2 = model2.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose = 2) #not good model, accuracy 40-50 flactuate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4000/4000 - 72s - loss: 0.6976 - accuracy: 0.5039 - val_loss: 0.6898 - val_accuracy: 0.5110\n",
            "Epoch 2/20\n",
            "4000/4000 - 73s - loss: 0.5866 - accuracy: 0.6729 - val_loss: 0.3999 - val_accuracy: 0.8318\n",
            "Epoch 3/20\n",
            "4000/4000 - 73s - loss: 0.3941 - accuracy: 0.8223 - val_loss: 0.3417 - val_accuracy: 0.8538\n",
            "Epoch 4/20\n",
            "4000/4000 - 74s - loss: 0.3257 - accuracy: 0.8616 - val_loss: 0.3179 - val_accuracy: 0.8641\n",
            "Epoch 5/20\n",
            "4000/4000 - 73s - loss: 0.2892 - accuracy: 0.8824 - val_loss: 0.2772 - val_accuracy: 0.8895\n",
            "Epoch 6/20\n",
            "4000/4000 - 74s - loss: 0.2671 - accuracy: 0.8934 - val_loss: 0.2627 - val_accuracy: 0.8947\n",
            "Epoch 7/20\n",
            "4000/4000 - 74s - loss: 0.2425 - accuracy: 0.9046 - val_loss: 0.2703 - val_accuracy: 0.8918\n",
            "Epoch 8/20\n",
            "4000/4000 - 74s - loss: 0.2291 - accuracy: 0.9100 - val_loss: 0.2561 - val_accuracy: 0.8994\n",
            "Epoch 9/20\n",
            "4000/4000 - 74s - loss: 0.2154 - accuracy: 0.9166 - val_loss: 0.2523 - val_accuracy: 0.9023\n",
            "Epoch 10/20\n",
            "4000/4000 - 75s - loss: 0.2033 - accuracy: 0.9221 - val_loss: 0.5032 - val_accuracy: 0.8127\n",
            "Epoch 11/20\n",
            "4000/4000 - 75s - loss: 0.1919 - accuracy: 0.9255 - val_loss: 0.4475 - val_accuracy: 0.8170\n",
            "Epoch 12/20\n",
            "4000/4000 - 75s - loss: 0.1843 - accuracy: 0.9299 - val_loss: 0.2392 - val_accuracy: 0.9082\n",
            "Epoch 13/20\n",
            "4000/4000 - 74s - loss: 0.1784 - accuracy: 0.9314 - val_loss: 0.2756 - val_accuracy: 0.8934\n",
            "Epoch 14/20\n",
            "4000/4000 - 74s - loss: 0.1655 - accuracy: 0.9376 - val_loss: 0.2396 - val_accuracy: 0.9093\n",
            "Epoch 15/20\n",
            "4000/4000 - 73s - loss: 0.1586 - accuracy: 0.9415 - val_loss: 0.2437 - val_accuracy: 0.9081\n",
            "Epoch 16/20\n",
            "4000/4000 - 73s - loss: 0.1558 - accuracy: 0.9408 - val_loss: 0.2394 - val_accuracy: 0.9070\n",
            "Epoch 17/20\n",
            "4000/4000 - 73s - loss: 0.1503 - accuracy: 0.9439 - val_loss: 0.3755 - val_accuracy: 0.8663\n",
            "Epoch 18/20\n",
            "4000/4000 - 73s - loss: 0.1412 - accuracy: 0.9469 - val_loss: 0.2549 - val_accuracy: 0.9084\n",
            "Epoch 19/20\n",
            "4000/4000 - 74s - loss: 0.1356 - accuracy: 0.9504 - val_loss: 0.2517 - val_accuracy: 0.9076\n",
            "Epoch 20/20\n",
            "4000/4000 - 74s - loss: 0.1338 - accuracy: 0.9505 - val_loss: 0.2660 - val_accuracy: 0.9047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avZpB_6ynBYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hidden layer 2 -> global avg poolinh\n",
        "model5 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(50,activation = 'relu'),\n",
        "        tf.keras.layers.Dense(25,activation = 'relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(12,activation = 'relu'),\n",
        "        f.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1,activation = 'sigmoid'),\n",
        "])\n",
        "model5.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xWe38m_7TUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09aefb5a-e84c-4ef5-ef3d-a70a3dab4cb0"
      },
      "source": [
        "num_epochs = 30\n",
        "batch_size = 10\n",
        "history5 = model5.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 2/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 3/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 4/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 5/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.4956 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 6/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 7/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 8/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 9/30\n",
            "4000/4000 - 78s - loss: 0.6931 - accuracy: 0.5041 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 10/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 11/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 12/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 13/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 14/30\n",
            "4000/4000 - 75s - loss: 0.6931 - accuracy: 0.5051 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 15/30\n",
            "4000/4000 - 74s - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 16/30\n",
            "4000/4000 - 73s - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 17/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 18/30\n",
            "4000/4000 - 73s - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 19/30\n",
            "4000/4000 - 73s - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 20/30\n",
            "4000/4000 - 73s - loss: 0.6932 - accuracy: 0.5031 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 21/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 22/30\n",
            "4000/4000 - 74s - loss: 0.6932 - accuracy: 0.4951 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 23/30\n",
            "4000/4000 - 74s - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 24/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.5026 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 25/30\n",
            "4000/4000 - 76s - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 26/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 27/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 28/30\n",
            "4000/4000 - 75s - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 29/30\n",
            "4000/4000 - 74s - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
            "Epoch 30/30\n",
            "4000/4000 - 74s - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.4970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6zOJ-rQ5bSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lstm\n",
        "# model3 = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "#     tf.keras.layers.LSTM(32),\n",
        "#     tf.keras.layers.Dense(16, activation='relu'),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuBhHGyz7W5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "662b5e16-b7d0-4b9a-f650-60314f10d9a3"
      },
      "source": [
        "num_epochs = 3\n",
        "batch_size = 10\n",
        "history3 = model3.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "  16/4000 [..............................] - ETA: 33:15:17 - loss: 0.6940 - accuracy: 0.4750"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6H8_rdf8GNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 6000\n",
        "embed_size = 80\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size,embed_size),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences = True)),\n",
        "    tf.keras.layers.GlobalMaxPool1D(),\n",
        "    tf.keras.layers.Dense(20,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "model7.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model7.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjR5M_2U-9Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 3\n",
        "history7 = model7.fit(training_padded, training_labels, batch_size=batch_size, epochs=epochs, validation_data=(testing_padded, testing_labels), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhYYv7C66oyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "b06dad24-c1d9-48a7-d765-c38d74fa933c"
      },
      "source": [
        "#mix of conv & lstm\n",
        "model4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model4.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 13741, 16)         800000    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 13741, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 13737, 64)         5184      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 3434, 64)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 838,273\n",
            "Trainable params: 838,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So2c-80KkxX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 30\n",
        "batch_size = 10\n",
        "history4 = model4.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roHxzawDJPXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model8.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model8.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtqQ-PVIlQYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')\n",
        "plot_graphs(history6, 'accuracy')\n",
        "plot_graphs(history6, 'loss')\n",
        "plot_graphs(history2, 'accuracy')\n",
        "plot_graphs(history2, 'loss')\n",
        "plot_graphs(history5, 'accuracy')\n",
        "plot_graphs(history5, 'loss')\n",
        "# plot_graphs(history3, 'accuracy')\n",
        "# plot_graphs(history3, 'loss')\n",
        "# plot_graphs(history4, 'accuracy')\n",
        "# plot_graphs(history4, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MW2XHSv3n7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}