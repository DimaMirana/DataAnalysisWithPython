{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Course 3 - Week 3 - Lesson 2d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimaMirana/DataAnalysisWithPython/blob/master/Copy_of_Course_3_Week_3_Lesson_2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P-AhVYeBWgQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54da9988-26a6-4121-c181-8b719ef513ce"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# !pip install -q tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_IoM4VFxWpMR",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHQ2Ko0zl7M4",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_data, test_data = imdb['train'], imdb['test']\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "# str(s.tonumpy()) is needed in Python3 instead of just s.numpy()\n",
        "for s,l in train_data:\n",
        "  training_sentences.append(str(s.numpy()))\n",
        "  training_labels.append(l.numpy())\n",
        "  \n",
        "for s,l in test_data:\n",
        "  testing_sentences.append(str(s.numpy()))\n",
        "  testing_labels.append(l.numpy())\n",
        "  \n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7n15yyMdmoH1",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9axf0uIXVMhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "16515b35-4f92-40ec-b7a8-880d4a4b2b96"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(decode_review(padded[2]))\n",
        "print(training_sentences[2])\n",
        "print(training_labels_final[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<OOV> photographs the <OOV> rocky mountains in a superb fashion and jimmy stewart and walter brennan give enjoyable performances as they always seem to do br br but come on hollywood a <OOV> telling the people of dawson city <OOV> to <OOV> themselves a <OOV> yes a <OOV> and to <OOV> the law themselves then <OOV> battling it out on the streets for control of the town br br nothing even remotely resembling that happened on the canadian side of the border during the <OOV> gold rush mr mann and company appear to have mistaken dawson city for <OOV> the canadian north for the american wild west br br canadian viewers be prepared for a <OOV> madness type of enjoyable\n",
            "b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5NEpdhb8AxID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6a57e2f9-89fe-4810-d7a1-4a9e2e2ea4ef"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 64)                9600      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 390       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 169,997\n",
            "Trainable params: 169,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5LLrXC-uNX6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b3e284c-dbae-4da4-b835-81ee22e99c51"
      },
      "source": [
        "num_epochs = 50\n",
        "history = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.5579 - accuracy: 0.6882 - val_loss: 0.3728 - val_accuracy: 0.8387\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.3176 - accuracy: 0.8710 - val_loss: 0.3526 - val_accuracy: 0.8470\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.2421 - accuracy: 0.9062 - val_loss: 0.3795 - val_accuracy: 0.8416\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.1910 - accuracy: 0.9298 - val_loss: 0.4088 - val_accuracy: 0.8354\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.1429 - accuracy: 0.9496 - val_loss: 0.4646 - val_accuracy: 0.8290\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.1052 - accuracy: 0.9650 - val_loss: 0.5599 - val_accuracy: 0.8134\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.6114 - val_accuracy: 0.8119\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.6860 - val_accuracy: 0.8124\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.8089 - val_accuracy: 0.8183\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0259 - accuracy: 0.9918 - val_loss: 0.8762 - val_accuracy: 0.8062\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 1.0154 - val_accuracy: 0.8070\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.9728 - val_accuracy: 0.8052\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 1.0840 - val_accuracy: 0.8139\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 1.2259 - val_accuracy: 0.8086\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 1.3149 - val_accuracy: 0.8035\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 1.2308 - val_accuracy: 0.8063\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 1.3303 - val_accuracy: 0.8069\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.3856 - val_accuracy: 0.8044\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.3281 - val_accuracy: 0.8072\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 1.2194 - val_accuracy: 0.8022\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 1.4608 - val_accuracy: 0.8060\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.4798 - val_accuracy: 0.8042\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 1.5436 - val_accuracy: 0.8142\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 1.3381 - val_accuracy: 0.8040\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.4564 - val_accuracy: 0.8058\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 1.5421 - val_accuracy: 0.7926\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.6731 - val_accuracy: 0.8027\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 9.0951e-05 - accuracy: 1.0000 - val_loss: 1.6558 - val_accuracy: 0.8072\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.0716e-05 - accuracy: 1.0000 - val_loss: 1.7308 - val_accuracy: 0.8060\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.9532e-05 - accuracy: 1.0000 - val_loss: 1.7928 - val_accuracy: 0.8064\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.3270e-05 - accuracy: 1.0000 - val_loss: 1.8567 - val_accuracy: 0.8072\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 9.0278e-06 - accuracy: 1.0000 - val_loss: 1.9213 - val_accuracy: 0.8067\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 6.0923e-06 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.8076\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 4.0857e-06 - accuracy: 1.0000 - val_loss: 2.0496 - val_accuracy: 0.8068\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.7059e-06 - accuracy: 1.0000 - val_loss: 2.1164 - val_accuracy: 0.8072\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.7815e-06 - accuracy: 1.0000 - val_loss: 2.1842 - val_accuracy: 0.8072\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.1686e-06 - accuracy: 1.0000 - val_loss: 2.2533 - val_accuracy: 0.8070\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 14s 19ms/step - loss: 7.6845e-07 - accuracy: 1.0000 - val_loss: 2.3211 - val_accuracy: 0.8068\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 5.0186e-07 - accuracy: 1.0000 - val_loss: 2.3907 - val_accuracy: 0.8068\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.2740e-07 - accuracy: 1.0000 - val_loss: 2.4621 - val_accuracy: 0.8066\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.1482e-07 - accuracy: 1.0000 - val_loss: 2.5297 - val_accuracy: 0.8064\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.4079e-07 - accuracy: 1.0000 - val_loss: 2.6006 - val_accuracy: 0.8061\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 9.2681e-08 - accuracy: 1.0000 - val_loss: 2.6695 - val_accuracy: 0.8063\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 6.0974e-08 - accuracy: 1.0000 - val_loss: 2.7371 - val_accuracy: 0.8061\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 4.0559e-08 - accuracy: 1.0000 - val_loss: 2.8042 - val_accuracy: 0.8062\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 2.7230e-08 - accuracy: 1.0000 - val_loss: 2.8681 - val_accuracy: 0.8062\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.8454e-08 - accuracy: 1.0000 - val_loss: 2.9321 - val_accuracy: 0.8062\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 1.2631e-08 - accuracy: 1.0000 - val_loss: 2.9961 - val_accuracy: 0.8060\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 8.8048e-09 - accuracy: 1.0000 - val_loss: 3.0545 - val_accuracy: 0.8061\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 6.2076e-09 - accuracy: 1.0000 - val_loss: 3.1100 - val_accuracy: 0.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nHGYuU4jPYaj",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSualgGPPK0S",
        "colab": {}
      },
      "source": [
        "# Model Definition with LSTM\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K_Jc7cY3Qxke",
        "colab": {}
      },
      "source": [
        "# Model Definition with Conv1D\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}